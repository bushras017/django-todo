name: Deploy Infrastructure

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: us-central1
  ZONE: us-central1-a

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4

      - name: Auth to GCP
        id: auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Extract Service Account Email
        id: sa-email
        run: |
          SA_EMAIL=$(echo '${{ secrets.GCP_SA_KEY }}' | jq -r '.client_email')
          echo "SA_EMAIL=$SA_EMAIL" >> $GITHUB_ENV

      - name: Setup Additional IAM Permissions
        run: |
          gcloud projects add-iam-policy-binding ${{ secrets.GCP_PROJECT_ID }} \
            --member="serviceAccount:${{ env.SA_EMAIL }}" \
            --role="roles/storage.admin"

          gcloud projects add-iam-policy-binding ${{ secrets.GCP_PROJECT_ID }} \
            --member="serviceAccount:${{ env.SA_EMAIL }}" \
            --role="roles/bigquery.dataEditor"
          
          gcloud projects add-iam-policy-binding ${{ secrets.GCP_PROJECT_ID }} \
            --member="serviceAccount:${{ env.SA_EMAIL }}" \
            --role="roles/logging.configWriter"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Create terraform.tfvars
        run: |
          cat > terraform/terraform.tfvars << EOF
          project_id = "${{ secrets.GCP_PROJECT_ID }}"
          region = "${{ env.REGION }}"
          zone = "${{ env.ZONE }}"
          db_password = "${{ secrets.DB_PASSWORD }}"
          notification_email = "${{ secrets.NOTIFICATION_EMAIL }}"
          notification_email_password = "${{ secrets.EMAIL_APP_PASSWORD }}"
          alert_email_recipients = ${{ secrets.ALERT_EMAILS }}
          service_account_email = "${{ env.SA_EMAIL }}"
          EOF

      - name: Terraform Init
        working-directory: ./terraform
        run: terraform init

      - name: Terraform Validate
        working-directory: ./terraform
        run: terraform validate

      - name: Clean and Import Resources
        working-directory: ./terraform
        run: |
          # Remove existing state
          terraform state rm google_compute_network.vpc || true
          terraform state rm google_compute_subnetwork.subnet || true
          terraform state rm google_compute_firewall.allow_monitoring || true
          terraform state rm google_compute_firewall.allow_django || true
          terraform state rm google_compute_firewall.allow_internal || true
          terraform state rm google_compute_instance.db_server || true
          terraform state rm google_compute_instance.web_server || true
          terraform state rm google_bigquery_dataset.security_logs || true
          terraform state rm google_pubsub_topic.prometheus_alerts || true
          terraform state rm google_storage_bucket.function_bucket || true
          terraform state rm google_cloudfunctions_function.alert_handler || true
          
          # Import resources
          echo "Importing VPC..."
          terraform import google_compute_network.vpc \
            "projects/${{ secrets.GCP_PROJECT_ID }}/global/networks/devsecops-vpc" || true
          
          echo "Importing subnet..."
          terraform import google_compute_subnetwork.subnet \
            "projects/${{ secrets.GCP_PROJECT_ID }}/regions/${{ env.REGION }}/subnetworks/devsecops-subnet" || true
          
          echo "Importing firewall rules..."
          terraform import google_compute_firewall.allow_monitoring \
            "projects/${{ secrets.GCP_PROJECT_ID }}/global/firewalls/allow-monitoring" || true
          
          terraform import google_compute_firewall.allow_django \
            "projects/${{ secrets.GCP_PROJECT_ID }}/global/firewalls/allow-django" || true
          
          terraform import google_compute_firewall.allow_internal \
            "projects/${{ secrets.GCP_PROJECT_ID }}/global/firewalls/allow-internal" || true
          
          echo "Importing compute instances..."
          terraform import google_compute_instance.db_server \
            "projects/${{ secrets.GCP_PROJECT_ID }}/zones/${{ env.ZONE }}/instances/db-server" || true
          
          terraform import google_compute_instance.web_server \
            "projects/${{ secrets.GCP_PROJECT_ID }}/zones/${{ env.ZONE }}/instances/web-server" || true
          
          echo "Importing BigQuery dataset..."
          terraform import google_bigquery_dataset.security_logs \
            "${{ secrets.GCP_PROJECT_ID }}:security_logs" || true
          
          echo "Importing Pub/Sub topic..."
          terraform import google_pubsub_topic.prometheus_alerts \
            "projects/${{ secrets.GCP_PROJECT_ID }}/topics/prometheus-alerts" || true
          
          echo "Importing storage bucket..."
          terraform import google_storage_bucket.function_bucket \
            "${{ secrets.GCP_PROJECT_ID }}-functions" || true
          
          echo "Importing cloud function..."
          terraform import google_cloudfunctions_function.alert_handler \
            "projects/${{ secrets.GCP_PROJECT_ID }}/locations/${{ env.REGION }}/functions/alert-handler" || true
          
          # Show the current state
          echo "Current Terraform State:"
          terraform state list

      - name: Terraform Plan
        if: github.event_name == 'pull_request'
        working-directory: ./terraform
        run: terraform plan

      - name: Prepare Cloud Function
        run: |
          if [ -d "cloud_function" ]; then
            cd cloud_function
            zip -r ../terraform/function.zip ./*
          else
            echo "Cloud function directory not found. Creating empty function.zip"
            touch empty.txt
            zip terraform/function.zip empty.txt
            rm empty.txt
          fi

      - name: Terraform Apply
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          cd terraform
          # First refresh the state
          terraform apply -refresh-only -auto-approve || true
          
          # Then apply changes
          terraform apply -auto-approve

      - name: Deploy Django App
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          # Get outputs
          WEB_IP=$(terraform -chdir=terraform output -raw web_server_public_ip)
          DB_IP=$(terraform -chdir=terraform output -raw db_server_private_ip)
          
          # Create Django environment file
          cat > .env << EOF
          DEBUG=False
          DJANGO_SECRET_KEY=${{ secrets.DJANGO_SECRET_KEY }}
          DB_NAME=${{ secrets.DB_NAME }}
          DB_USER=${{ secrets.DB_USER }}
          DB_PASSWORD=${{ secrets.DB_PASSWORD }}
          DB_HOST=$DB_IP
          DB_PORT=5432
          ALLOWED_HOSTS=$WEB_IP,localhost,127.0.0.1
          GOOGLE_CLOUD_PROJECT=${{ secrets.GCP_PROJECT_ID }}
          EOF

          # Get instance user and escape any special characters
          INSTANCE_USER=$(gcloud compute ssh web-server --zone=${{ env.ZONE }} --command "whoami" | tr -d '\n')
          # Get instance user and escape any special characters
          INSTANCE_USER=$(gcloud compute ssh web-server --zone=${{ env.ZONE }} --command "whoami" | tr -d '\n')
          echo "Instance user is: $INSTANCE_USER"

          # Create deployment directory
          echo "Setting up deployment directory..."
          DEPLOY_DIR="deploy_package"
          mkdir -p $DEPLOY_DIR
          
          # Copy application files
          cp -r manage.py requirements.txt todoApp todos staticfiles $DEPLOY_DIR/
          cp .env $DEPLOY_DIR/
          mkdir -p $DEPLOY_DIR/staticfiles

          # Prepare Gunicorn service file
          echo "Preparing Gunicorn service file..."
          cp gunicorn.service $DEPLOY_DIR/
          # Use perl instead of sed for more reliable string replacement
          perl -pi -e "s/USER_PLACEHOLDER/${INSTANCE_USER}/g" "$DEPLOY_DIR/gunicorn.service"

          # Copy files to web server
          echo "Copying files to web server..."
          gcloud compute scp --recurse $DEPLOY_DIR/* web-server:/opt/django-app/ --zone=${{ env.ZONE }}
          gcloud compute scp $DEPLOY_DIR/.env web-server:/opt/django-app/ --zone=${{ env.ZONE }}
          
          # Setup services and application
          gcloud compute ssh web-server --zone=${{ env.ZONE }} --command "
            # Copy service file
            sudo cp /opt/django-app/gunicorn.service /etc/systemd/system/
            sudo chmod 644 /etc/systemd/system/gunicorn.service

            # Setup Django and Gunicorn
            cd /opt/django-app && \
            python3 -m venv venv && \
            source venv/bin/activate && \
            python3 -m pip install --upgrade pip && \
            python3 -m pip install -r requirements.txt gunicorn && \
            python3 manage.py migrate && \
            python3 manage.py collectstatic --noinput && \
            
            # Start service
            sudo systemctl daemon-reload && \
            sudo systemctl enable gunicorn && \
            sudo systemctl restart gunicorn"

          # Verify the deployment
          echo "Verifying deployment..."
          gcloud compute ssh web-server --zone=${{ env.ZONE }} --command "
            echo '=== Gunicorn Service Status ==='
            sudo systemctl status gunicorn
            
            if ! sudo systemctl is-active gunicorn; then
              echo '=== Service File Content ==='
              cat /etc/systemd/system/gunicorn.service
              echo '=== Gunicorn Service Logs ==='
              sudo journalctl -u gunicorn --no-pager -n 50
              exit 1
            fi"

      - name: Setup Prometheus on Web Server
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          # Get Web Server IP
          WEB_IP=$(terraform -chdir=terraform output -raw web_server_public_ip)
          echo "Using Web IP: $WEB_IP"

          # Create temporary directory for configs
          mkdir -p prometheus_configs

          # Create Prometheus config
          cat > prometheus_configs/prometheus.yml << EOF
          global:
            scrape_interval: 15s
            evaluation_interval: 15s

          rule_files:
            - /etc/prometheus/rules/*.yml

          scrape_configs:
            - job_name: 'django'
              metrics_path: '/prometheus/metrics'
              static_configs:
                - targets: ['$WEB_IP:8000']
                  labels:
                    instance: 'web-server'

            - job_name: 'node'
              static_configs:
                - targets: ['$WEB_IP:9100']
                  labels:
                    instance: 'web-server'

          alerting:
            alertmanagers:
              - static_configs:
                  - targets: ['$WEB_IP:9093']
          EOF

          # Create alert rules
          cat > prometheus_configs/alerts.yml << EOF
          groups:
          - name: django_alerts
            rules:
            - alert: FailedLoginAttempt
              expr: increase(django_failed_login_total[1m]) >= 1
              for: 10s
              labels:
                severity: warning
              annotations:
                summary: Failed Login Attempt
                description: "Failed login attempt detected from {{ \$labels.ip }}"

            - alert: HighCPUUsage
              expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: High CPU Usage
                description: "CPU usage is above 80% on {{ \$labels.instance }}"
          EOF

          # Create Alertmanager config
          cat > prometheus_configs/alertmanager.yml << EOF
          global:
            resolve_timeout: 5m

          route:
            group_by: ['alertname']
            group_wait: 10s
            group_interval: 10s
            repeat_interval: 1h
            receiver: 'pubsub'

          receivers:
            - name: 'pubsub'
              webhook_configs:
                - url: 'http://$WEB_IP:9095/alerts'
          EOF

          # Copy all configs to web server
          gcloud compute scp --recurse prometheus_configs/* web-server:/tmp/ --zone=${{ env.ZONE }}

          # Setup and configure on web server
          gcloud compute ssh web-server --zone=${{ env.ZONE }} -- bash -c '
            set -e

            # Install required packages
            sudo apt-get update
            sudo apt-get install -y prometheus prometheus-alertmanager prometheus-node-exporter

            # Create directories
            sudo mkdir -p /etc/prometheus/rules
            sudo mkdir -p /etc/alertmanager

            # Move config files
            sudo mv /tmp/prometheus.yml /etc/prometheus/
            sudo mv /tmp/alerts.yml /etc/prometheus/rules/
            sudo mv /tmp/alertmanager.yml /etc/alertmanager/

            # Set permissions
            sudo chown -R prometheus:prometheus /etc/prometheus
            sudo chown -R prometheus:prometheus /etc/alertmanager
            sudo chmod -R 644 /etc/prometheus/prometheus.yml /etc/prometheus/rules/alerts.yml /etc/alertmanager/alertmanager.yml
            sudo chmod 755 /etc/prometheus/rules

            # Create systemd override directories
            sudo mkdir -p /etc/systemd/system/prometheus.service.d
            sudo mkdir -p /etc/systemd/system/prometheus-alertmanager.service.d
            sudo mkdir -p /etc/systemd/system/prometheus-node-exporter.service.d

            # Create override files
            echo "[Service]
            ExecStart=
            ExecStart=/usr/bin/prometheus \\
              --web.listen-address=:9090 \\
              --config.file=/etc/prometheus/prometheus.yml \\
              --storage.tsdb.path=/var/lib/prometheus \\
              --web.enable-lifecycle" | sudo tee /etc/systemd/system/prometheus.service.d/override.conf

            echo "[Service]
            ExecStart=
            ExecStart=/usr/bin/alertmanager \\
              --web.listen-address=:9093 \\
              --config.file=/etc/alertmanager/alertmanager.yml \\
              --storage.path=/var/lib/alertmanager" | sudo tee /etc/systemd/system/prometheus-alertmanager.service.d/override.conf

            echo "[Service]
            ExecStart=
            ExecStart=/usr/bin/prometheus-node-exporter \\
              --web.listen-address=:9100" | sudo tee /etc/systemd/system/prometheus-node-exporter.service.d/override.conf

            # Reload systemd and restart services
            sudo systemctl daemon-reload
            sudo systemctl restart prometheus
            sudo systemctl restart prometheus-alertmanager
            sudo systemctl restart prometheus-node-exporter

            # Wait for services to start
            sleep 5

            # Verify services are running
            services="prometheus prometheus-alertmanager prometheus-node-exporter"
            for service in $services; do
              if ! sudo systemctl is-active --quiet $service; then
                echo "$service is not running"
                sudo systemctl status $service
                exit 1
              fi
            done

            # Test endpoints
            endpoints="9090 9093 9100"
            for port in $endpoints; do
              if ! curl -s localhost:$port > /dev/null; then
                echo "Port $port is not responding"
                sudo netstat -tlpn | grep $port
                exit 1
              fi
            done

            echo "All services are running and responding"
          '

          # Final verification
          echo "Testing endpoints..."
          for port in 9090 9093 9100; do
            if curl -s "http://$WEB_IP:$port" > /dev/null; then
              echo "Port $port is accessible"
            else
              echo "Port $port is not accessible"
            fi
          done

          echo "Setup complete. Access points:"
          echo "Prometheus: http://$WEB_IP:9090"
          echo "Alertmanager: http://$WEB_IP:9093"
          echo "Node Exporter: http://$WEB_IP:9100/metrics"
          echo "Django metrics: http://$WEB_IP:8000/prometheus/metrics"
    
      - name: Run Lynis Security Scan
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          # Run Lynis on web server
          gcloud compute ssh web-server --zone=${{ env.ZONE }} --command "
            sudo lynis audit system --quick --no-colors > /opt/django-app/logs/lynis-web.log 2>&1"

          echo "Security scans completed and logged"